{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913ea05e",
   "metadata": {},
   "source": [
    "# PageRank: Uma visão de Álgebra Linear\n",
    "\n",
    "### Introdução\n",
    "\n",
    "(Muitos dos quais lerão esse texto, raramente em sua vida, se depararam com o problema de ter que utilizar outro site de busca, além do Google, para encontrar algo que procura na internet. Porém, quando ela ainda estava em sua fase “jovem”, isso era um problema comum.)\n",
    "    \n",
    "Praticamente todo mundo que você conhece usa o Google. Uns ou outros utilizam o Bing e algumas pessoas perdidas no tempo \n",
    "usam o Yahoo!. Mas, algo razoável de se perguntar é: sempre foi assim? Provavelmente a resposta a essa pergunta é: Nem \n",
    "sempre. [posso reler a introdução do livro para ter ideias boas do que adicionar aqui.]\n",
    "    |\n",
    "Mas então, **por que** o Google é _o Google_? A resposta disso em uma palavra é: PageRank.\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "### PageRank\n",
    "    \n",
    "PageRank é um algoritmo criado por Sergey Brin e Larry Page, os fundadores da Google, no final de década de 90, que utiliza\n",
    "a estrutura de _links_ da Internet para dar uma classificação a suas páginas.\n",
    "\n",
    "A ideia central do algoritmo é resumida na seguinte frase: uma página é importante se páginas importantes levam a ela. Em\n",
    "minha opinião, isso parece um pouco recursivo demais. Uma página será importante se outras páginas que ligam a ela forem \n",
    "importantes. Agora, essas páginas são importantes porque outras páginas importantes ligam a elas. Seguindo nesse \n",
    "raciocínio, chegamos na seguinte pergunta: quem são \"as primeiras\" páginas importantes? Essa recursão, na verdade, é algo\n",
    "embutido no algoritmo, algo que é trabalhado para se calcular a classificação de cada página. Conforme o texto, mais \n",
    "especificamente na seção de matemática, for progredindo, essa ideia ficará mais clara e veremos que, na verdade, não\n",
    "precisam existir \"as primeiras\" páginas importantes.\n",
    "\n",
    "Um fato curioso sobre o PageRank é que ele utiliza, praticamente, somente conceitos básicos da Álgebra Linear. Sim, um dos \n",
    "grandes motivos do porquê a _Google_ ser tão poderosa no mercado tecnológico de hoje em dia é devido, no seu início como \n",
    "empresa, à implementação de Álgebra Linear básica em algoritmos. Qualquer um que já fez algum curso de Álgebra Linear \n",
    "possui as ferramentas básicas para entender _como_ e o _por que_ o PageRank funciona. Esse é justo o foco central deste \n",
    "texto.\n",
    "    \n",
    "    \n",
    "    \n",
    "## A Matemática por trás\n",
    "\n",
    "### A Matriz G\n",
    "\n",
    "Para começarmos, suponha um conjunto $P$ com $n$ páginas da Internet dadas por $P_i \\ (i = 1,2,\\cdots,n)$. Suponha também\n",
    "que as páginas desse conjunto possuem _links_ que vão para páginas do mesmo conjunto. Uma forma interessante de visualizar \n",
    "as páginas de $P$ e as ligações entre elas é por meio de um grafo. Por motivos didáticos, usaremos um conjunto $P$ com \n",
    "$n = 7$ páginas dadas pelo grafo abaixo.\n",
    "![Grafo](https://raw.githubusercontent.com/rangelalbuq/PageRank/main/Imagens/Grafo_1.png)\n",
    "Na imagem, os nós (círculos) representam as páginas e as arestas (setas) representam as ligações entre as páginas.\n",
    "\n",
    "Podemos representar esse grafo em um formato matricial. Seja $A$ uma matriz tal que $A_{ij}$ = 1, se a página $i$ possuí\n",
    "um link para a página $j$, e $A_{ij}$ = 0 caso contrário (a página i não possui um _link_ para a página j). Acabamos de \n",
    "criar uma chamada matriz de _Adjacência_ do grafo.\n",
    "Assim, a matriz $A$ do grafo do conjunto de páginas $P$ é dada por\n",
    "\n",
    "$$ A =\n",
    "\\begin{bmatrix}\n",
    "            0&1&0&0&0&0&0 \\\\\n",
    "            0&0&1&0&0&0&0\\\\\n",
    "            1&0&0&1&0&0&1\\\\\n",
    "            0&0&0&0&1&0&0\\\\\n",
    "            0&0&0&0&0&1&0\\\\\n",
    "            0&0&0&1&0&0&0\\\\\n",
    "            0&0&0&0&0&0&0\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "Agora, vamos olhar para a matriz $A$ de uma forma diferente. E se o elemento $A_{ij}$ representasse a probabilidade de um \n",
    "usuário da internet ir à página $j$ considerando o fato dele estar, agora no momento, na página $i$? Observando $A$, vemos\n",
    "que essa interpretação nova não está consoante com ela e que um problema já visível está em sua linha 3. Segundo\n",
    "nossa interpretação, se um usuário estiver na página 3, a probabilidade dele ir para página 1 é igual à 1. Porém, a chance \n",
    "dele ir para as páginas 4 e 7 também é 1, algo que não faz sentido. Um modo de contornar esse problema é criar uma _nova_ \n",
    "matriz que tenha a mesma “cara” de  $A$ e que também, corresponda com essa nova interpretação probabilística.\n",
    "\n",
    "Um modo de criar essa nova matriz, digamos $H$, de forma que, as probabilidades sejam “justas” ou “sem viés” é pela\n",
    "seguinte definição: o elemento $H_{ij}$ é igual à $(\\sum_{k=1}^{n}H_{ik})^{-1}$ se a página $i$ possuí um _link_ para \n",
    "a página $j$ e $H_{ij} = 0$ caso contrário. Embora pareça um pouco complicado essa nova definição, saiba que a \n",
    "única diferença entra ela e a de $A$ é que estamos “normalizando” as linhas não-nulas para que a soma entre seus\n",
    "elementos seja igual à 1 e assim, faça sentido pensar nela como probabilidade. Assim, $H$ será dada por,\n",
    "\n",
    "$$ H = \n",
    "\\begin{bmatrix}\n",
    "            0&1&0&0&0&0&0 \\\\\n",
    "            0&0&1&0&0&0&0\\\\\n",
    "            1/3&0&0&1/3&0&0&1/3\\\\\n",
    "            0&0&0&0&1&0&0\\\\\n",
    "            0&0&0&0&0&1&0\\\\\n",
    "            0&0&0&1&0&0&0\\\\\n",
    "            0&0&0&0&0&0&0\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "A matriz $H$ agora é uma _matriz subestocástica_. Porém, ainda na matriz $H$ temos um problema. E a linha 7? Ela, por sua\n",
    "vez, possuí uma linha completa de zeros, o que quer dizer pela nossa interpretação que, se um usuário estiver na página 7,\n",
    "a probabilidade dele ir para qualquer outra página (de $P$) é zero. O que intuitivamente quer dizer que ele ficará na\n",
    "página 7 **para sempre**. Obviamente, isso é algo que não queremos que aconteça com nosso modelo, que a página 7 seja um \n",
    "“buraco negro” para nossos usuários, em que, se eles chegarem lá, viverão para sempre.\n",
    "\n",
    "Faremos o seguinte para contornar esse fato: se uma linha contiver apenas zeros, ela será alterada de forma que, todos \n",
    "seus elementos sejam iguais à $\\frac{1}{n}$, em que $n$ é o número de páginas de $P$ (dimensão de $H$). O que isso\n",
    "interpretativamente faz é que caso um usuário chegue a uma página que não possua ligação alguma com outra, ele escolhe\n",
    "“aleatoriamente” (com a mesma probabilidade) uma página qualquer de $P$ para ir.\n",
    "\n",
    "Assim, a matriz $H$ “atualizada”, o qual chamaremos de $S$, é dada por\n",
    "\n",
    "$$ S = \n",
    "\\begin{bmatrix}\n",
    "            0&1&0&0&0&0&0 \\\\\n",
    "            0&0&1&0&0&0&0\\\\\n",
    "            1/3&0&0&1/3&0&0&1/3\\\\\n",
    "            0&0&0&0&1&0&0\\\\\n",
    "            0&0&0&0&0&1&0\\\\\n",
    "            0&0&0&1&0&0&0\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7 \n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "A matriz $S$ agora é uma _matriz estocástica_.\n",
    "\n",
    "Porém, _incrivelmente_, ainda há mais um problema (e o último) com nosso modelo! Se, você leitor, observasse a matriz $S$ \n",
    "por um tempo suficientemente grande, provavelmente iria notar a seguinte propriedade da matriz: Se um usuário estiver na \n",
    "página 4, ele irá para a página 5. Se estiver na página 5, ele irá para a página 6. E se estiver na página 6, ele irá para\n",
    "a\n",
    "página 4. E assim por diante, para sempre. Criando assim um _loop_ eterno da navegação do mesmo. E com isso, a \n",
    "partir do momento em que entra pela primeira vez em uma dessas páginas, as outras ($P_i$ com $i= 1,2,3,7$) efetivamente \n",
    "“não existirão” mais em nosso modelo, assim, não será possível quantificar algum tipo de classificação para as mesmas, mas \n",
    "apenas para aquelas que estão no ciclo.\n",
    "\n",
    "Para que o fato discutido acima não ocorra, consideraremos mais uma, e última modificação no comportamento do nosso \n",
    "usuário. Agora, antes de simplesmente selecionar um _link_ na página que atualmente se encontra, o usuário terá uma \n",
    "probabilidade $1 - \\alpha$ (com $\\alpha \\in (0,1)$) de ir para uma página qualquer de $P$. Isso, além trazer propriedades\n",
    "que garantirão o exito de nosso modelo, algo que veremos posteriormente, ela também traz a ele um comportamento\n",
    "esperado de qualquer um que navega a Internet. É razoável esperar de uma pessoa que ela não somente vá sendo levada site a\n",
    "site seguindo apenas os _links_ da página em que se encontra. Ela também pode, por exemplo, entrar em algum site em que a\n",
    "aba está aberta em seu navegador, ou também, abrir um de seu histórico por livre e espontânea vontade.\n",
    "\n",
    "A nova matriz criada a partir de $S$ será a chamada _matriz Google $G$_. Ela é dada pela seguinte equação:\n",
    "\n",
    "$$ G = \\alpha S + (1 - \\alpha)1/nee^T . $$\n",
    "\n",
    "Em que $1/nee^T \\in \\mathbb{R}^{n \\times n}$ é uma matriz de “teleportação aleatória”, o qual todos seus elementos são \n",
    "iguais à $\\frac{1}{n}$.\n",
    "Em nosso exemplo, escolhendo $\\alpha = 0.85$ a matriz G é\n",
    "\n",
    "$$\n",
    "G = 0.85\n",
    "\\begin{bmatrix}\n",
    "            0&1&0&0&0&0&0 \\\\\n",
    "            0&0&1&0&0&0&0\\\\\n",
    "            1/3&0&0&1/3&0&0&1/3\\\\\n",
    "            0&0&0&0&1&0&0\\\\\n",
    "            0&0&0&0&0&1&0\\\\\n",
    "            0&0&0&1&0&0&0\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7 \n",
    "\\end{bmatrix}\n",
    "+ 0.15\n",
    "\\begin{bmatrix}\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\\\\\n",
    "            1/7&1/7&1/7&1/7&1/7&1/7&1/7\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "(Agora o que nos resta é, de fato, calcular a tanta aclamada classificação das páginas de $P$ numericamente utilizando a \n",
    "matriz $G$ para certo $\\alpha$. Para isso veremos uma rápida introdução do método (usualmente mais) utilizado para o\n",
    "cálculo do PageRank: O Método da Potência.)\n",
    "\n",
    "### Fórmula para o PageRank\n",
    "\n",
    "Seguindo a filosofia de que _uma página é importante se páginas importantes direcionam a ela_, vamos definir uma \n",
    "fórmula para calcular o $PageRank$ de uma página. Uma possível fórmula poderia simplesmente ser a soma dos PageRanks das\n",
    "outras páginas que apontam para ela, assim sendo\n",
    "$$\n",
    "r(P_i) = \\sum_{P_j \\in B_{P_i}}{r(P_j)},\n",
    "$$\n",
    "em que $r(P_i)$ é o PageRank da página $i$, $r(P_j)$ o da página $j$ e $B_{P_i}$ é o conjunto das páginas que apontam \n",
    "para a página $i$. Como cada $r(P_i)$ é um _rank_, temos que $r(P_i) > 0$. Para que o valor de algum $r(P_i)$ não \n",
    "\"exploda\", será também imposto a condição de que $\\sum_{i=1}^n r(P_i) = 1$.\n",
    "\n",
    "Porém, se questione do seguinte: imagine duas páginas os quais possuem o mesmo PageRank. Uma dessas páginas possui apenas \n",
    "um link para uma página qualquer, enquanto a outra possui links para cem páginas. O peso do link da primeira página deve \n",
    "ser o mesmo que o peso de cada link da segunda?\n",
    "\n",
    "Para os criadores do Google, a resposta é não. Quanto mais links uma página há, a \"importância\" de cada um\n",
    "desses links deve valer menos. Portanto, para a fórmula do PageRank, é preciso ter um fator de peso o qual mede o quão\n",
    "\"expressivo\" é um link.\n",
    "\n",
    "Assim, a fórmula inicialmente usada por Sergey Brin e Larry Page é\n",
    "$$\n",
    "r(P_i) = \\sum_{P_j \\in B_{P_i}}\\frac{r(P_j)}{|P_j|},\n",
    "$$\n",
    "em que $|P_j|$ é o número de links de $P_j$.\n",
    "\n",
    "O problema óbvio com essa fórmula é a de que simplesmente não sabemos os valores de $r(P_j)$. A forma utilizada para lidar \n",
    "com isso será aplicar a fórmula sucessivamente para as páginas de $P$, utilizando, a cada nova iteração, os valores obtidos \n",
    "para $r(P_j)$ da iteração prévia e torcer para que os valores de $r(P_j)$ convirjam para algo _estável_. Assim, \n",
    "introduzindo uma nova notação, temos\n",
    "\n",
    "$$ \n",
    "r_{k+1}(P_i) = \\sum_{P_j \\in B_{P_i}}\\frac{r_k(P_j)}{|P_j|}.\n",
    "$$\n",
    "\n",
    "Para que a fórmula acima faça sentido, é preciso ainda saber quem são os $r_0(P_i)$, $i = 1,\\dots, n$, que é justo nossa \n",
    "dúvida inicial discutida na seção \"PageRank\". Como inicialmente conhecemos nada sobre as páginas $P_i$, é razoável pensar \n",
    "que todas, no começo do processo, valem o mesmo. Portanto a condição inicial dos $r(P_i)$ será $r_0(P_i) = \\frac{1}{n}$ \n",
    "para $i = 1,\\dots, n$.\n",
    "\n",
    "Agora que a mágica começa a acontecer. Pela equação acima, temos um sistema de $n$ equações em que cada uma depende da\n",
    "outra. Em todas, os $r(P_i)$ são \"pesados\" por diferentes coeficientes a cada equação, contando também com a \"pesagem\" por \n",
    "$0$. E ainda por cima, há um somatório em todas equações. Isso está cheirando uma multiplicação matriz-vetor. E de fato, \n",
    "esse sistema realmente pode ser representado desta forma.\n",
    "\n",
    "Os $r(P_i)$, $i = 1, \\dots, n$ serão as componentes de um vetor $\\pi$ e os \"pesos\" $|P_i|$, $i = 1,\\dots, n$ farão\n",
    "parte da matriz de coeficientes.\n",
    "\n",
    "Visto que há condições impostas à $r(P_i)$, $\\pi^t$ também terá. Primeiramete, temos que $r(P_i) = \\pi^t_i > 0$ o que\n",
    "implica em $\\pi^t > 0$. E também que como $\\sum_{i=1}^n r(P_i) = \\sum_{i=1}^n |r(P_i)| = 1$ isso significa que \n",
    "$\\|\\pi^t\\|_1 = 1$.\n",
    "\n",
    "Agora você leitor, consegue lembrar de alguma matriz que era composta por \"pesos\", que juntos somavam a $1$ e que dependiam\n",
    "somente do quanto de _links_ uma página $P_i$ possuía para outras páginas? Essa é justo a matriz $H$. Para lembrança,\n",
    "a matriz $H$ do exemplo é\n",
    "\n",
    "$$ H = \n",
    "\\begin{bmatrix}\n",
    "            0&1&0&0&0&0&0 \\\\\n",
    "            0&0&1&0&0&0&0\\\\\n",
    "            1/3&0&0&1/3&0&0&1/3\\\\\n",
    "            0&0&0&0&1&0&0\\\\\n",
    "            0&0&0&0&0&1&0\\\\\n",
    "            0&0&0&1&0&0&0\\\\\n",
    "            0&0&0&0&0&0&0\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "O que nos falta agora é se decidir se a multiplicação será dada pela direita, $\\pi_{k+1} = H\\pi_k$, ou pela esquerda,\n",
    "$\\pi^T_{k+1} = \\pi^T_kH$. Como os elementos de uma coluna $i$ de $H$ representam as probabilidades do usuário na página da \n",
    "linha $j$ ir a página $i$, esses são justos \"pesos\" da fórmula. Assim, a multiplicação matriz-vetor deve ser feito pela \n",
    "esquerda.\n",
    "\n",
    "$$\n",
    "\\pi^T_{k+1}\n",
    "=\n",
    "\\pi^T_kH\n",
    ".\n",
    "$$\n",
    "\n",
    "Porém, como já foi discutido na seção \"A Matriz G\", sabemos que a utilização da matriz $H$ trás problemas para o \n",
    "modelo. Portanto, em vez de $\\pi^t_k$ ser multiplicado por $H$, ele será multiplicado por $G$. Deste modo tem-se,\n",
    "\n",
    "$$\n",
    "\\pi^T_{k+1}\n",
    "=\n",
    "\\pi^T_kG\n",
    ".\n",
    "$$\n",
    "\n",
    "Uma implicação \"ruim\" do uso da $G$ na equação é que ela não nos dará o \"real\" ranqueamento de cada página. Isso se deve ao \n",
    "fato de $G$ ser o resultado de uma soma entre $S$ e $ee^t$. A matriz $S$ preserva a estrutura de links das páginas da \n",
    "Internet e lida de forma \"especial\" com páginas sem links. Enquanto $ee^t$, que é uma matriz de teleportação aleatória, não \n",
    "preserva a estrutura. Ainda sim é necessário a utilização de $G$ para, pelo menos, obter uma aproximação do \"real\" _rank_ \n",
    "das páginas. Não é possível de se calcular este \"real\" _rank_, utilizando somente $S$. Apenas o uso dela pode acarretar no \n",
    "fenômeno do usuário fictício seguir um caminho periódico previsível entre as páginas, algo que foi visto na seção \"A matriz \n",
    "G\". Ou, de  forma mais geral, o usuário navegar somente num conglomerado de páginas sem ter a possibilidade do mesmo \n",
    "conseguir  \"chegar\" em alguma página fora desse conglomerado. Em qualquer um desses casos, o _PageRank_ das páginas que não \n",
    "pertencem a esse conglomerado iria tender a zero conforme o cálculo dos _ranks_ for sendo executado. O que implica na falha \n",
    "do modelo para o cálculo do _rank_ dessas páginas, algo não desejado.\n",
    "\n",
    "Como esperamos que os elementos de $\\pi$, $\\pi^t_i = r(P_i)$, convirjam para um valor estável depois de várias\n",
    "iterações, temos que para um $k$ \"grande\", $\\pi^t_k \\approx \\pi^t_{k+1}$. Assim podemos escrever que para $k\\rightarrow\n",
    "\\infty$, $\\pi^t_k = \\pi^t$ em que $\\pi^t$ satisfaz\n",
    "$$\n",
    "\\pi^t\n",
    "=\n",
    "\\pi^tG.\n",
    "$$\n",
    " \n",
    "Deste modo, o problema do _PageRank_ se reduz a encontrar um vetor $\\pi^t$ que satisfaz as condições $\\pi^t > 0$, \n",
    "$\\|\\pi^t\\|_1$ = 1 e também $\\pi^t = \\pi^tG$.\n",
    "\n",
    "### Autovalor e Autovetor\n",
    "\n",
    "Agora antes de continuar, uma pequena pausa no racicíonio para relembrar o conceito de autovalor e autovetor que será\n",
    "importante para o entendimento deste texto.\n",
    "\n",
    "Você provavelmente está acostumado com a seguinte definição de autovalor e autovetor: dada uma matriz qualquer $A \\in \n",
    "\\mathbb{R}^{n \\times n}$ e um vetor $v \\in \\mathbb{R}^n$, com $v \\neq 0$, $v$ é autovetor de $A$ associado ao autovalor $\\lambda$ se\n",
    "$$ Av = \\lambda v,$$\n",
    "para algum $\\lambda \\in \\mathbb{R}$. Uma forma de se calcular os autovalores $\\lambda$ é pelo _polinômio característico_  \n",
    "de $A$, $p(A) = det(A-\\lambda I)$.\n",
    "\n",
    "Porém, mesmo A possuindo apenas entradas reais, as raízes de $p(A)$ podem assumir valores complexos. Assim, se nos\n",
    "restringirmos a valores reais para os autovalores $\\lambda$, é possível que haja a \"perda\" de certos $\\lambda$. Isso \n",
    "implicaria que a \"quantidade\" (multiplicidade algébrica) de autovalores de $A$ seja menor do que $n$, sua dimensão, o que \n",
    "implicaria em problemas para nossa análise. Portanto, para que nenhum autovalor $\\lambda$ fique de fora, será adotada a \n",
    "seguinte definição de autovalor e autovetor:\n",
    "\n",
    "Dada uma matriz $A \\in \\mathbb{C}^{n \\times n}$ e um vetor $v \\in \\mathbb{C}^n$, com $v \\neq 0$. $v$ é autovetor de $A$ \n",
    "associado ao autovalor $\\lambda$ se\n",
    "$$ Av = \\lambda v,$$\n",
    "para algum $\\lambda \\in \\mathbb{C}$.\n",
    "\n",
    "O conjunto de autovalores $\\lambda$ que uma matriz $A$ possuí será chamado de espectro de A, denotado por $\\sigma(A)$.\n",
    "\n",
    "Será visto mais adiante que o foco dos cálculos envolve um autovalor real. Como G, _a matriz Google_, assume \n",
    "apenas valores reais, os vetores os quais são multiplicados por $G$ também só possuirão valores reais. Dito isso só será\n",
    "utilizada a aritmética real, que estamos mais acostumados a trabalhar.\n",
    "\n",
    "Uma observação importante a ser abordada é que existem tanto autovetor à direita quanto à esquerda. Os autovetores à\n",
    "direita são os que estamos mais habituados a lidar. Mas não se preocupe, se você entende autovetores à direita você também\n",
    "entende o à esquerda. É praticamente a mesma ideia. Algo não difícil de provar é que o espectro\n",
    "$\\sigma(A)$ de uma matriz A (o conjunto dos autovalores de uma matriz) dos autovetores à direita e dos \n",
    "à esquerda de $A$ é o mesmo (tente provar você mesmo!), assim, se existem autovetores à direita para um certo \n",
    "$\\lambda$ irá também existir autovetores à esquerda para o mesmo $\\lambda$. Porém há sim, certas diferenças entre ambos, \n",
    "como por exemplo que se um vetor $v$ é autovetor à direita associado a um autovalor $\\lambda$ isso não implica que $v^t$ \n",
    "também será autovetor à esquerda associado a $\\lambda$.\n",
    "\n",
    "\n",
    "[falar que a norma 1 de $\\pi^t$ é igual à 1 e discutir sobre o autovalor 1 de $\\pi^t_{k+1} = \\pi^t_kG \\rightarrow \\pi^t = \\pi^tG$, provavelmente vou criar um nova seção para isso]\n",
    "\n",
    "### O Método da Potência [seção foi escrita antes do que a seção Fórmula para o PageRank]\n",
    "\n",
    "Até ao momento no texto, não vimos algo \"muito\" relacionado à Álgebra Linear. Diria que poderia ser mais encaixado nos \n",
    "conceitos básicos de Geometria Analítica (matrizes, o conceito de dimensão, etc). Porém a partir de agora, e até ao final \n",
    "do texto, iremos ver ideias mais sofisticadas de Algelin.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "113da935",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "Cell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
